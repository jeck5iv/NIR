{
  "batch_size": 1,
  "num_train_epochs": 5,
  "gradient_accumulation_steps": 4,
  "fp16": true,
  "learning_rate": 1e-4,
  "logging_steps": 10,
  "eval_strategy": "epoch",
  "save_strategy": "epoch",
  "output_dir": "checkpoints_shared",
  "logging_dir": "logs_shared",
  "save_total_limit": 2
}
