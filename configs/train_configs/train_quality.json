{
  "batch_size": 8,
  "gradient_accumulation_steps": 4,
  "num_train_epochs": 3,
  "fp16": true,
  "learning_rate": 2e-4,
  "logging_steps": 10,
  "eval_strategy": "epoch",
  "save_strategy": "epoch",
  "output_dir": "checkpoints",
  "logging_dir": "logs",
  "save_total_limit": 2
}
