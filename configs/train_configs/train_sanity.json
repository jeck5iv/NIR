{
  "batch_size": 1,
  "num_train_epochs": 0.01,
  "gradient_accumulation_steps": 1,
  "fp16": true,
  "learning_rate": 1e-4,
  "logging_steps": 1,
  "eval_strategy": "no",
  "save_strategy": "epoch",
  "save_total_limit": 1,
  "output_dir": "checkpoints",
  "logging_dir": "logs"
}
